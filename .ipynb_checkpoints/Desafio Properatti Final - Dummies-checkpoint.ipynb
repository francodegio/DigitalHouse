{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio Properati - Limpieza de datos - Grupo 3\n",
    "\n",
    "En este proyecto el desafío es limpiar la base de datos de inmuebles provista por Properati.\n",
    "\n",
    "El objetivo de la limpieza es dejar listo el dataset para luego poder utilizarlo para hacer regresiones y calcular el valor de nuevas observaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo lo vamos a hacer?\n",
    "Decidimos estructurar nuestras tareas en cuatro bloques de trabajo:\n",
    "* 1: Análisis exploratorio. \n",
    "* 2: Normalizar, corregir y rellenar la informacion que lo permita, sin afectar prediciones futuras.\n",
    "* 3: Quitar todo lo que no nos sirve.\n",
    "* 4: Calcular las variables dummies y mostrar los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Análisis exploratorio\n",
    "\n",
    "A partir del analisis exploratorio de los datos, ponemos a prueba algunas de las hipótesis que tendremos en cuenta para estandarizar la información. \n",
    "En los casos en los que nuestras hipótesis se corroboran, definimos las estrategias que tomaremos para corregir el dataset en el siguiente bloque de trabajo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/Leandro/anaconda3/lib/python3.7/site-packages/fiona/ogrext.cpython-37m-darwin.so, 2): Library not loaded: @rpath/libkea.1.4.7.dylib\n  Referenced from: /Users/Leandro/anaconda3/lib/libgdal.20.dylib\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a31dea58ea75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfolium\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/geopandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_points_from_xy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpoints_from_xy\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_file\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_postgis\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msjoin\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeoSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fiona/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PATH\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PATH\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\";\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlibdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytesCollection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCollection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrvsupport\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msupported_drivers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mensure_env_with_credentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fiona/collection.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvfs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mogrext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mItemsIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeysIterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mogrext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mogrext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuffer_to_virtual_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_virtual_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGEOMETRY_TYPES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/Leandro/anaconda3/lib/python3.7/site-packages/fiona/ogrext.cpython-37m-darwin.so, 2): Library not loaded: @rpath/libkea.1.4.7.dylib\n  Referenced from: /Users/Leandro/anaconda3/lib/libgdal.20.dylib\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import re\n",
    "from IPython.core.display import HTML\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# usado para pruebas hechas sobre  las urls de imagenes y link a las publicaciones\n",
    "import requests \n",
    "import hashlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importo archivo\n",
    "df = pd.read_csv(\"properatti.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos los porcentajes de datos faltantes de cada columna\n",
    "for cols in df.columns:\n",
    "    nulos = df[cols].isnull().sum()\n",
    "    porcentaje = nulos/len(df)\n",
    "    print(f'{porcentaje*100:.0f}%', cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con respecto a los datos faltantes, rápidamente podemos descartar variables que son innecesarias, tales como:\n",
    "`properati_url`, `Unnamed:0`, `lat` y `lon`. Estas últmas  2, no son necesarias ya que contamos con `lat-lon` que tiene mayor precisión.\n",
    "\n",
    "Por otra parte, existen demasiados datos faltantes de las variables `floor` y `expenses`, por lo que sería conveniente descartarlas por completo. \n",
    "\n",
    "En cuanto a una las variables críticas del modelo, vemos que `rooms` tiene un 61% de datos faltantes, lo que requiere dedicación para extraer datos de los títulos y descripciones. También es alarmante que no existan datos de **baños**, **dormitorios**, **amenities** o de **cocheras**, por lo que sería conveniente al menos intentar extraer datos relacionados.\n",
    "\n",
    "Finalmente, las variables relacionadas a las coordenadas geográficas tienen datos sobre el 57% de la muestra y lamentablemente no es factible intentar extraerla ya que no es información que se pueda conseguir en las descripciones. Afortunadamente contamos con información de los barrios y localidades en la variable `place_with_parent_names`, lo que nos permite generar dummies y calcular matrices de ponderación espacial por contigüidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajos exploratorios con la superficie de las propiedades:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trabajo  sobre m2 en superficie total y superficie cubierta con valores invertidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscamos los casos en los que la superficie total es menor que la superficie cubierta.\n",
    "print(\"Muestra de M2 con superficie total menor que superficie cubierta\")\n",
    "display(df.loc[(df.surface_total_in_m2 < df.surface_covered_in_m2),[\"surface_total_in_m2\",\"surface_covered_in_m2\"]].sample(5))\n",
    "\n",
    "\n",
    "#Suponemos que los valores de las columnas de superficie total y superficie cubierta pueden estar invertidos por error. \n",
    "#Estimamos la división de uno sobre otro para calcular la media de esta diferencia que nos permita corroborar nuestra hipótesis.\n",
    "df['cubierta_sobre_total'] = df['surface_total_in_m2']/ df['surface_covered_in_m2'] \n",
    "df['total_sobre_cubierta'] = df['surface_covered_in_m2']/ df['surface_total_in_m2']\n",
    "df['valores_invertidos'] = df['surface_covered_in_m2'] < df['surface_total_in_m2']\n",
    "\n",
    "#Dropeamos los valores iguales para que no afecten el promedio.\n",
    "#Observamos que son valores similares y que por lo tanto nos permiten asumir que los valores de ambas columnas fueron invertidos.\n",
    "print(\"Resumen de la media de la relacion de variables sobre M2 (valores invertidos y no invertidos)\")\n",
    "display(\n",
    "    df.drop(df.loc[df['surface_total_in_m2'] == df['surface_covered_in_m2']].index)\\\n",
    "    [[\"valores_invertidos\",\"total_sobre_cubierta\",\"cubierta_sobre_total\"]].groupby(['valores_invertidos']).mean()\n",
    ")\n",
    "\n",
    "# Por esto decidimo invertir los valores de las columnas de superficie total y superficie cubierta en aquellos casos que la primera es inferior a la segunda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trabajo sobre m2 en superficie total y superficie cubierta según tipo de propiedad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contamos los casos que tienen una superficie total inferior a superficie cubierta según tipo de propiedad.\n",
    "print ('Casos con superifice total inferior a superficie cubierta por tipo de propiedad')\n",
    "display (df.loc[(df.surface_total_in_m2 < df.surface_covered_in_m2)]['property_type'].value_counts())\n",
    "\n",
    "print ('--------------')\n",
    "\n",
    "#Contamos casos segun tipo de propiedad para obtener relacion porcentual. Concluimos que no es una variable significativa para etsa relación.\n",
    "print ('Casos totales por tipo de propiedad')\n",
    "display (df['property_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trabajo  para completar m2 a partir del valor de la propiedad y del valor por metro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Solo puedo averiguar mi incognita si tengo metros y valor por metro\n",
    "# ejemplo: x = df['price_aprox_usd']/df['price_usd_per_m2']\n",
    "\n",
    "#Buscamos las diferentes combinaciones\n",
    "print(\"USD, Con Precio y PPM USD pero sin M2: {}\".format(\n",
    "    df.loc[(~df[\"price_aprox_usd\"].isnull()) & (~df[\"price_usd_per_m2\"].isnull()) & (df[\"surface_total_in_m2\"].isnull()),\"operation\"].count()\n",
    "))\n",
    "print(\"ARS, Con Precio y PPM ARS pero sin M2: {}\".format(\n",
    "    df.loc[(~df[\"price_aprox_local_currency\"].isnull()) & (~df[\"price_per_m2\"].isnull()) & (df[\"surface_total_in_m2\"].isnull()),\"operation\"].count()\n",
    "))\n",
    "print(\"Con Precio default y PPM default pero sin M2: {}\".format(\n",
    "    df.loc[(~df[\"price\"].isnull()) & (~df[\"price_per_m2\"].isnull()) & (df[\"surface_total_in_m2\"].isnull()),\"operation\"].count()\n",
    "))\n",
    "print(\"Con Precio default y PPM USD pero sin M2: {}\".format(\n",
    "    df.loc[(~df[\"price\"].isnull()) & (~df[\"price_usd_per_m2\"].isnull()) & (df[\"surface_total_in_m2\"].isnull()),\"operation\"].count()\n",
    "))\n",
    "\n",
    "# Hipotesis refutada, no sirve para obtener nuevos datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trabajo para completar m2 a partir de valores útiles en título y descripción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una regex  y la corremos en titulo y en descripcion para ver que encuentra\n",
    "pattern= r'([\\.\\d]{2,99}) (?!m²|m2|mt|metro)'\n",
    "m2ExtractedFromTitle=df.loc[df[\"surface_total_in_m2\"].isnull(),'title'].str.extract(pattern, re.IGNORECASE)\n",
    "m2FromDescription=df.loc[df[\"surface_total_in_m2\"].isnull(),'description'].str.extract(pattern, re.IGNORECASE)\n",
    "\n",
    "# Imprimir resumen resultados\n",
    "print(\"Valores en columna titulo: {}\".format(m2ExtractedFromTitle.dropna().describe().loc[\"count\",0]))\n",
    "print(\"Valores en columna descripcion: {}\".format(m2FromDescription.dropna().describe().loc[\"count\",0]))\n",
    "\n",
    "\n",
    "# Imprimir lo encontrado en titulo.\n",
    "df[\"m2Extracted\"] = m2ExtractedFromTitle\n",
    "for index,x in df.iloc[m2ExtractedFromTitle.dropna().index].loc[:,[\"title\",\"m2Extracted\"]].iterrows():\n",
    "    print(\"\\r Found: {}  \\t Title: {}  \".format(x[\"m2Extracted\"],x[\"title\"]))\n",
    "\n",
    "    \n",
    "# Dropeamos columna temporal\n",
    "df.drop(\"m2Extracted\",axis=1,inplace=True)\n",
    "\n",
    "#Tras revisar los resultados, hay muchas informacion falsa y no es confiable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trabajo  para completar cantidad de ambientes con valores útiles en título y descripción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una regex  y la corremos en título y en descripcíon para ver que encuentra\n",
    "pat_ambientes = r'\\b(\\d{1,2})\\s*amb'\n",
    "\n",
    "#Extraemos los datos las nuevas columnas amb_tit y amb_desc del título y la descripcion\n",
    "df['amb_tit'] = df.title.str.extract(pat_ambientes, re.IGNORECASE, expand=True).astype(np.float)\n",
    "df['amb_desc'] = df.description.str.extract(pat_ambientes, re.IGNORECASE, expand=True).astype(np.float)\n",
    "\n",
    "#Verificamos los valores extraídos\n",
    "print (\"Cantidad de ambientes extraídos de títulos:\")\n",
    "display (df.loc[~(df.amb_tit.isnull())].filter(['amb_tit']).sort_values('amb_tit').amb_tit.unique())\n",
    "print (\"Cantidad de ambientes extraídos de descripciones:\")\n",
    "display (df.loc[~(df.amb_desc.isnull())].filter(['amb_desc']).sort_values('amb_desc').amb_desc.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras revisar los resultados,  concluimos que en las descripciones hay mucha información falsa y no confiable. \n",
    "Optamos solo por extraer los valores del título. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trabajo para completar cantidad de dormitorios con valores útiles en título y descripción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una regex  y la corremos en título y en descripción para ver que encuentra\n",
    "pat_dormitorios = r'\\b(\\d{1,2})\\s*dor'\n",
    "\n",
    "#Extraemos los datos a las nuevas columnas dor_tit y dor_desc del título y la descripcion\n",
    "df['dor_tit'] = df.title.str.extract(pat_dormitorios, re.IGNORECASE, expand=True).astype(np.float)\n",
    "df['dor_desc'] = df.description.str.extract(pat_dormitorios, re.IGNORECASE, expand=True).astype(np.float)\n",
    "\n",
    "#Verificamos los valores extraídos\n",
    "print (\"Cantidad de dormitorios extraídos de títulos:\")\n",
    "display (df.loc[~(df.dor_tit.isnull())].filter(['dor_tit']).sort_values('dor_tit').dor_tit.unique())\n",
    "print (\"Cantidad de dormitorios extraídos de descripciones:\")\n",
    "display (df.loc[~(df.dor_desc.isnull())].filter(['dor_desc']).sort_values('dor_desc').dor_desc.unique()\n",
    ")\n",
    "#Tras revisar los resultados, optamos por no tomar ninguno de los datos extraidos dado que mucha información es falsa y no confiable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trabajo para recuperar cantidad de baños con valores útiles en título y descripción: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una regex  y la corremos en título y en descripción para ver que encuentra\n",
    "pat_banos = r'\\b(\\d{1,2})\\s*bañ'\n",
    "\n",
    "#Extraemos los datos a las nuevas columnas bath_tit y bath_desc del título y la descripcion\n",
    "df['bath_tit'] = df.title.str.extract(pat_banos, re.IGNORECASE, expand=True).astype(np.float)\n",
    "df['bath_desc'] = df.description.str.extract(pat_banos, re.IGNORECASE, expand=True).astype(np.float)\n",
    "\n",
    "#Verificamos los valores extraídos\n",
    "print (\"Cantidad de baños extraídos de títulos:\")\n",
    "display (df.loc[~(df.bath_tit.isnull())].filter(['bath_tit']).sort_values('bath_tit').bath_tit.unique())\n",
    "print (\"Cantidad de baños extraídos de descripciones:\")\n",
    "display (df.loc[~(df.bath_desc.isnull())].filter(['bath_desc']).sort_values('bath_desc').bath_desc.unique())\n",
    "\n",
    "#Tras revisar los resultados, optamos por no tomar ninguno de los datos extraidos dado que el volumen de datos que extraemos no es significativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, cuando extraemos datos de la descripción, tenemos mezclados la cantidad de ambientes y los metros de algún ambiente, por lo cual no los consideraremos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trabajo para completar los datos faltantes de 'rooms' a partir de los datos de ambientes obtenidos en títulos:\n",
    "\n",
    "Tomamos un subset compuesto por las observaciones que tienen valores en la variable `rooms` y los que también tienen en el título, es decir `amb_tit` y hacemos un booleano entre dichas Series.\n",
    "\n",
    "Lo que nos devuelve es una serie de booleanos, que tienen la propiedad de que los valores `True` son iguales a 1, mientras que los `False` son 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ambientes = df.filter(['amb_tit', 'dor_tit', 'rooms']).\\\n",
    "        loc[~(df.rooms.isnull()) & ~(df.amb_tit.isnull())].amb_tit.astype(np.float64) == \\\n",
    "    df.filter(['amb_tit', 'dor_tit', 'rooms']).loc[~(df.rooms.isnull()) & ~(df.amb_tit.isnull())].rooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos la suma total de los valores, donde nos dará el total de `True`s, y lo dividimos en la longitud total de la serie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambientes.sum()/len(ambientes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado anterior indica que rooms y ambientes es lo mismo en un 94% de los casos, por lo que podemos rellenar los `NaN` de *'rooms'* con *'amb_tit'*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Llenamos los `NaN` con los valores obtenidos en `amb_tit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisamos cuantos podemos salvar\n",
    "df.loc[(df.rooms.isnull()) & (~df.amb_tit.isnull())]\n",
    "\n",
    "#Llenamos los NaN's verificando cuales no tienen valores en rooms\n",
    "display(df.loc[~df.rooms.isnull()].shape)\n",
    "\n",
    "#Hacemos el fillna\n",
    "df.rooms.fillna(df.amb_tit, inplace=True)\n",
    "\n",
    "'Observaciones con datos de ambientes:',df.loc[~df.rooms.isnull()].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trabajo sobre la variable `lat-lon`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos la variable en 2\n",
    "lat_lon = df['lat-lon'].str.split(',', expand=True)\n",
    "lat_lon = lat_lon.rename({0:'lat', 1:'lon'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiramos las variables innecesarias y unimos al dataframe original\n",
    "df = df.drop(['lat-lon', 'lat', 'lon'], axis=1).join(lat_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# los convertimos en float.\n",
    "df['lat'] = df.lat.astype(np.float)\n",
    "df['lon'] = df.lon.astype(np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajos exploratiorios con precios de las propiedades:\n",
    "\n",
    "Me centrare en las columnas 'place_name', 'price', 'currency', 'price_aprox_local_currency', 'price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2', 'price_usd_per_m2', 'price_per_m2'\n",
    "\n",
    "Tenemos 20 mil casos sin ningun dato de precio. Creo el DF dfprecio para trabajar todo lo relacionado a precio en el:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycolums = df[['place_name', 'price', 'currency', 'price_aprox_local_currency',\n",
    "               'price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2',\n",
    "               'price_usd_per_m2', 'price_per_m2', 'title', 'description']];\n",
    "dfprecio = mycolums.loc[((df['price'].isnull()) & (df['price_aprox_usd'].isnull())\\\n",
    "                         &(df['price_aprox_local_currency'].isnull()) \\\n",
    "                         &(df['price_usd_per_m2'].isnull()) & (df['price_per_m2'].isnull()))];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraigo precios de los titulos y descripciones. Creo 2 dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patron_p = r'([$]|[Uu][Ss$][$SDsd]*)\\s*(\\d*)[\\s* .,]*(\\d*)[\\s* .,](\\d*)'\n",
    "df_precio_desc = dfprecio['description'].str.extract(patron_p)\n",
    "df_precio_title = dfprecio['title'].str.extract(patron_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajos exploratorios con la ubicación de las propiedades: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Trabajo para recuperar ubicación faltante de las propiedades desde geonames\n",
    "Descargamos de acá: https://download.geonames.org/export/dump/ la base de datos de geonames de argentina\n",
    "Leemos la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_column_names = [\"geonameid\",\"name\",\"asciiname\",\"alternatenames\",\"lat\",\"lon\",\n",
    "                    \"feature class\",\"feature code\",\"country code\",\"cc2\",\n",
    "                    \"admin1 code\",\"admin2 code\",\"admin3 code\",\"admin4 code\",\"population\",\n",
    "                    \"elevation\",\"dem\",\"timezone\",\"modification date\"]\n",
    "\n",
    "geo = pd.read_csv(\"AR.txt\",sep='\\t',index_col=0,names=geo_column_names,)\n",
    "\n",
    "# Muestra de datos relevantes\n",
    "print(\"Shape de la base de datos: {}\".format(geo.shape))\n",
    "print(\"Muestra de datos de la DB de geonames\")\n",
    "display(geo[[\"name\",\"lat\",\"lon\"]].sample(5))\n",
    "\n",
    "# Joineamos las tablas por el id de geoname\n",
    "geodf=df.join(geo[[\"lat\",\"lon\"]],on=\"geonames_id\",rsuffix=\"_geo\")\n",
    "\n",
    "# Imprimo resultados encontrados\n",
    "print(\"\")\n",
    "print(\"Encontramos datos de latitud y longitud que no teniamos para {} observaciones\".format(geodf.loc[(geodf[\"lat\"].isnull()) & (~geodf[\"lat_geo\"].isnull())].shape[0]))\n",
    "print(\"No pudimos encontrar nuevos datos de latitud y longitud para {} observaciones\".format(geodf.loc[(~geodf[\"lat\"].isnull()) & (geodf[\"lat_geo\"].isnull())].shape[0]))\n",
    "print(\"Nuestro Dataset original podria quedar solo con {} observaciones sin latitud y longitud\".format(geodf.loc[(geodf[\"lat\"].isnull()) & (geodf[\"lat_geo\"].isnull())].shape[0]))\n",
    "print(\"\")\n",
    "print(\"Muestra de resultados con datos existentes y encontrados en Base de geonames\")\n",
    "geodf.loc[(~geodf[\"lat\"].isnull()) & (~geodf[\"lat_geo\"].isnull()),[\"place_with_parent_names\",\"geonames_id\",\"lat-lon\",\"lat\",\"lon\",\"lat_geo\",\"lon_geo\"]].sample(10)\n",
    "\n",
    "#CONCLUSIÓN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusión\n",
    "Con esta metodología se pueden obtener datos de latitud y longitud pero con menor precisión. Por el momento no las incluiremos en el dataset final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajo exploratorio con url de imágenes:\n",
    "##### Trabajo con duplicación de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizamos los primeros 100 casos, leemos la imagen, y le hacemos un hash para comparar a ver si es exacta igual a otra.\n",
    "r = pd.DataFrame([\n",
    "    hashlib.md5(requests.get(url = df.loc[x,\"image_thumbnail\"], params = []).text.encode()).hexdigest() for x in range(100)\n",
    "])\n",
    "# Imprimo  cantidad de duplicados\n",
    "print(\"Cantidad de imagenes duplicadas (con distinta url) de las primeras 100 observaciones {} \".format(r.duplicated().sum()))\n",
    "\n",
    "#Concluimos que no es una variable significativa ya que cuenta con imágenes duplicadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Normalizar, corregir y rellenar información\n",
    "\n",
    "En este bloque pretendemos llevar a cabo lo concluido a partir del análisis exploratorio. El objetivo es estandarizar la información del dataset, corrigiendo y completando datos faltantes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajos realizados sobre superficie de las propiedades:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Corregimos m2 que encontramos invertidos entre superficie total y superficie cubierta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo columna temporal_dos para filtrar subconjunto de datos relevantes a invertir\n",
    "df['temporal_dos'] = (df.surface_total_in_m2 < df.surface_covered_in_m2)\n",
    "print(\"Cantidad de registros a invertir entre Superficies total y cubierta: {}\".format(df['temporal_dos'].sum()))\n",
    "\n",
    "#Creo columna temporal para guardar datos\n",
    "df['temporal'] = df.surface_total_in_m2 \n",
    "\n",
    "#Paso valores de superficie cubierta a superficie total\n",
    "df.loc[df['temporal_dos'],'surface_total_in_m2'] = df.loc[df['temporal_dos'],'surface_covered_in_m2']\n",
    "\n",
    "#Paso valores de superficie total a superficie cubierta\n",
    "df.loc[df['temporal_dos'], 'surface_covered_in_m2'] = df.loc[df['temporal_dos'], 'temporal']\n",
    "\n",
    "#Recreamos la columna temporal para ver si siguen existiendo valores invertidos\n",
    "df['temporal_dos'] = (df.surface_total_in_m2 < df.surface_covered_in_m2)\n",
    "print(\"Cantidad de registros que siguen invertidos: {}\".format(df['temporal_dos'].sum()))\n",
    "\n",
    "#Dropeamos las temporales\n",
    "df.drop('temporal', axis=1, inplace=True)\n",
    "df.drop('temporal_dos', axis=1, inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Limpiamos nulls en variables de superficie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los metros en cero en superficie totales los ponemos en null\n",
    "print(\"Valores M2 cubierto en cero puestos en Nan: {}\".format((df[\"surface_covered_in_m2\"] == 0).sum()))\n",
    "print(\"Valores M2 totales en cero puestos en Nan: {}\".format((df[\"surface_total_in_m2\"] == 0).sum()))\n",
    "df.loc[(df[\"surface_total_in_m2\"] == 0),[\"surface_total_in_m2\"]] = np.nan\n",
    "df.loc[(df[\"surface_covered_in_m2\"] == 0),[\"surface_covered_in_m2\"]] = np.nan\n",
    "print(\"-------------\")\n",
    "\n",
    "#Revisamos valores antes del reemplazo\n",
    "print(\"Antes del reemplazo\")\n",
    "print(\"Nulos en totales: {}\".format(df['surface_total_in_m2'].isnull().sum()))\n",
    "print(\"Nulos en cubiertos: {}\".format(df['surface_covered_in_m2'].isnull().sum()))\n",
    "print(\"Nulos en ambos al mismo tiempo: {}\".format(df.loc[(df['surface_covered_in_m2'].isnull()) & (df['surface_total_in_m2'].isnull()) ,:].loc[:,\"operation\"].count()))\n",
    "print(\"Nulos totales y no en cubiertos: {}\".format(df.loc[(~df['surface_covered_in_m2'].isnull()) & (df['surface_total_in_m2'].isnull()) ,:].loc[:,\"operation\"].count()))\n",
    "print(\"Nulos cubierto y no en totales: {}\".format(df.loc[(df['surface_covered_in_m2'].isnull()) & (~df['surface_total_in_m2'].isnull()) ,:].loc[:,\"operation\"].count()))\n",
    "print(\"Valores iguales: {}\".format(df.loc[df['surface_total_in_m2'] == df['surface_covered_in_m2'],\"surface_covered_in_m2\"].count()))\n",
    "\n",
    "\n",
    "# relleno los m2totales faltantes con los cubiertos\n",
    "df.loc[(~df['surface_covered_in_m2'].isnull()) & ( df['surface_total_in_m2'].isnull()) ,\"surface_total_in_m2\"] = df[\"surface_covered_in_m2\"]\n",
    "# relleno los m2cubiertos faltantes con los totales\n",
    "df.loc[( df['surface_covered_in_m2'].isnull()) & (~df['surface_total_in_m2'].isnull()) ,\"surface_covered_in_m2\"] = df[\"surface_total_in_m2\"]\n",
    "print(\"-------------\")\n",
    "\n",
    "#Revisamos valores despues del reemplazo\n",
    "print(\"Despues del reemplazo\")\n",
    "print(\"Nulos en totales: {}\".format(df['surface_total_in_m2'].isnull().sum()))\n",
    "print(\"Nulos en cubiertos: {}\".format(df['surface_covered_in_m2'].isnull().sum()))\n",
    "print(\"Nulos en ambos al mismo tiempo: {}\".format(df.loc[(df['surface_covered_in_m2'].isnull()) & (df['surface_total_in_m2'].isnull()) ,:].loc[:,\"operation\"].count()))\n",
    "print(\"Nulos totales y no en cubiertos: {}\".format(df.loc[(~df['surface_covered_in_m2'].isnull()) & (df['surface_total_in_m2'].isnull()) ,:].loc[:,\"operation\"].count()))\n",
    "print(\"Nulos cubierto y no en totales: {}\".format(df.loc[(df['surface_covered_in_m2'].isnull()) & (~df['surface_total_in_m2'].isnull()) ,:].loc[:,\"operation\"].count()))\n",
    "print(\"Valores iguales: {}\".format(df.loc[df['surface_total_in_m2'] == df['surface_covered_in_m2'],\"surface_covered_in_m2\"].count()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajos realizados sobre el precio de las propiedades:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sumarizamos los resultados de los grupos de captura y creamos un nuevo dataframe con esos datos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precio_title['sumat'] = df_precio_title[1] + df_precio_title[2] + df_precio_title[3]\n",
    "df_precio_desc['sumad'] = df_precio_desc[1] + df_precio_desc[2] + df_precio_desc[3]\n",
    "df_precio_title = df_precio_title.iloc[:,[0,4]]\n",
    "df_precio_desc = df_precio_desc.iloc[:,[0,4]]\n",
    "df_precio_title['sumat'].fillna(0, inplace = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminamos NaNs y strings vacios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precio_title.replace(\"\", 0);\n",
    "df_precio_desc['sumad'] = df_precio_desc.sumad.str.strip();\n",
    "df_precio_desc.replace(\"\", 0, inplace=True)\n",
    "df_precio_desc['sumad'].fillna(0 ,inplace=True)\n",
    "dfpredesc2 = pd.merge(df_precio_desc, df_precio_title, how='outer', on=df_precio_desc.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unificamos los datos obtenidos via regex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpredesc2['sumad'] = pd.to_numeric(dfpredesc2['sumad'])\n",
    "dfpredesc2['sumat'] = pd.to_numeric(dfpredesc2['sumat'])\n",
    "dfpredesc2['final'] = dfpredesc2[['sumad','sumat']].max(axis=1)\n",
    "dfpredesc2.loc[(dfpredesc2['0_x'].isnull())&(dfpredesc2['0_y'].notnull()),'0_x']=dfpredesc2['0_y'];\n",
    "df_precio = dfpredesc2.loc[(dfpredesc2['final']!= 0) & (dfpredesc2['final']!= 1)].filter(['0_x','0_y', 'final'])\n",
    "del df_precio['0_y']\n",
    "df_precio.rename(columns = {'0_x':'moneda'}, inplace=True)\n",
    "dfprecio['price'].fillna(df_precio['final'], inplace=True)\n",
    "dfprecio['currency'].fillna(df_precio['moneda'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incorporamos los datos obtenidos al Data Frame original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfprecio.rename(columns={'price':'precio_regex','currency':'moneda'}, inplace = True)\n",
    "df = df.join(dfprecio[['precio_regex', 'moneda']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajos realizados sobre la ubicación de las propiedades: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Desagregamos los datos contenidos en place_with_parent_names: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliteamos columna place_with_parent_names y nombramos a las nuevas columnas\n",
    "place_split = df.place_with_parent_names.str\\\n",
    "                .split('|', expand=True).rename({1:'pais', 2:'provincia',\n",
    "                                                 3:'localidad', 4:'barrio'}, axis=1).drop([0,5,6], axis=1)\n",
    "\n",
    "# las que tienen datos vacios en barrios, las reemplazamos por NaN's\n",
    "place_split.loc[(place_split.barrio == ''), 'barrio'] = np.nan\n",
    "\n",
    "#Lo adjuntamos al df original\n",
    "df = df.join(place_split)\n",
    "df\n",
    "\n",
    "#Eliminamos las columnas ahora innecesarias \n",
    "df.drop([\"place_with_parent_names\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quitar todo lo que no nos sirve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta etapa de trabajo eliminamos todos aquellos datos que no serán necesarios para la construicción de nuestro modelo de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eliminamos duplicados: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestro forma inicial\n",
    "display(df.shape)\n",
    "\n",
    "# Buscar índices de registros duplicados (sin tener en cuenta las urls y la 1er columna de autonumerico)\n",
    "duplicados=df.loc[df.drop(\"Unnamed: 0\",axis=1).drop(\"properati_url\",axis=1).drop(\"image_thumbnail\",axis=1).duplicated(keep=\"last\")]\n",
    "print(\"Registros duplicados: {}\".format(duplicados[\"operation\"].count()))\n",
    "\n",
    "\n",
    "# DROP duplicados\n",
    "df.drop(duplicados.index, inplace=True)\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eliminamos columnas redundantes que no agregan al modelo de predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos columnas sin uso\n",
    "def drop_column(column,df):\n",
    "    try:\n",
    "        df.drop(column,axis=1,inplace=True)\n",
    "        print(\"Dropeando columna {} \".format(column));\n",
    "    except:\n",
    "        print(\"Columna {} ya dropeada \".format(column)) ;\n",
    "    \n",
    "# Muestro forma inicial\n",
    "display(df.shape)\n",
    "\n",
    "# properati_url: no tiene ningun uso de valor predictivo\n",
    "drop_column(\"properati_url\",df)\n",
    "\n",
    "# image_thumbnail: como se vió antes, hay imágenes duplicadas para departamentos distintos\n",
    "drop_column(\"image_thumbnail\",df)\n",
    "\n",
    "# unnamed 0: replica el indice en cada linea\n",
    "drop_column(\"Unnamed: 0\",df)\n",
    "\n",
    "# operation: siempre es venta, no suma nada al modelo\n",
    "drop_column(\"operation\",df)\n",
    "\n",
    "# country_name: siempres es argentina, no suma a modelo\n",
    "drop_column(\"country_name\",df)\n",
    "\n",
    "\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rellenamos los valores de los precios que recuperamos de títulos (rehacer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df.price.isnull(), 'currency'] = df.moneda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df.price.isnull(), 'price'] = df.precio_regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eliminamos observaciones contienen la frase \"en pozo\", \"cuotas\" o \"financiacion\" en la descrpción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observamos cuantas observaciones son\n",
    "df['pozo'] = df.description.str.extract(r'(\\ben\\spozo)', re.IGNORECASE, expand=True)\n",
    "display(df.loc[~(df.pozo.isnull())])\n",
    "\n",
    "df['cuota'] = df.description.str.extract(r'(\\bcuota)', re.IGNORECASE, expand=True)\n",
    "df['financ'] = df.description.str.extract(r'(\\financ)', re.IGNORECASE, expand=True)\n",
    "\n",
    "#Eliminamos dichos datos \n",
    "df.drop(df.loc[~(df.pozo.isnull())].index, axis=0, inplace=True)\n",
    "df.drop(df.loc[~(df.cuota.isnull())].index, axis=0, inplace=True)\n",
    "df.drop(df.loc[~(df.financ.isnull())].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación dropeamos los precios que son irrelevantes, tales como 0, 1 y 11111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df.price==0].index, axis=0, inplace=True)\n",
    "df.drop(df.loc[(df.price==1) | (df.price==11111) | (df.price==111111) |\\\n",
    "               (df.price==1111111) | (df.price==11111111)].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calcular las variables dummies y mostrar los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tenemos casi 9 mil casos. Genero dummy de Amenities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d_ameni = pd.get_dummies(df['description'].str.contains(r'(Amenities|amenit[ies]*[i]*[y]*)')).iloc[:, 1:]\n",
    "d_ameni.rename(columns={True : 'Amenities'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tenemos 30 mil casos con Pileta. Generamos la dummy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_pile = pd.get_dummies(df['description'].str.contains(r'([pP]isci|[pP]isin|[pP]isci|[Pp]ileta)')).iloc[:, 1:]\n",
    "d_pile.rename(columns={True : 'Pileta'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hay 32 mil casos con parrilla, generamos la dummy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_parri = pd.get_dummies(df['description'].str.contains(r'([pP]arril)')).iloc[:, 1:]\n",
    "d_parri.rename(columns={True : 'Parrilla'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hay 30 mil casos con laundy, genero dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_lava = pd.get_dummies(df['description'].str.contains(r'([Ll]aundr|andr|lavader)')).iloc[:, 1:]\n",
    "d_lava.rename(columns={True : 'Lavadero'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hay 5500 casos con SUM, genero las dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_salon = pd.get_dummies(df['description'].str.contains(r'([Ss][Uu][Mm] )')).iloc[ :, 1:]\n",
    "d_salon.rename(columns={True : 'SUM'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hay 10 mil casos con Seguridad privada. Genero dummies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_seguri = pd.get_dummies(df['description'].str.contains(r'([Ss]eguri)')).iloc[ :, 1:]\n",
    "d_seguri.rename(columns={True : 'Seguridad'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hay 7mil casos de propiedades a estrenar, generamos dummies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_estre = pd.get_dummies(df['description'].str.contains(r'([Ee]stren)')).iloc[ :, 1:]\n",
    "d_estre.rename(columns={True : 'Estrenar'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hay 42mil casos con cochera, genero las dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_coche = pd.get_dummies(df['description'].str.contains(r'([Cc]ochera|[Gg]arag)')).iloc[:, 1:]\n",
    "d_coche.rename(columns={True : 'Cochera'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hay casi 9 mil casos con gimnasio, genero dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gim = pd.get_dummies(df['description'].str.contains(r'([Gg][iy]m)')).iloc[:, 1:]\n",
    "d_gim.rename(columns={True : 'Gimnasio'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unifico las dummies en un nuevo dataframe consolidado y lo exporto para continuar con el en la parte 2 del TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "dfs_list = ['Amenities',d_ameni,'Cochera', d_coche,'Estrenar', d_estre,'Gimnasio', d_gim,'Lavadero', d_lava,'Parrilla', d_parri,'Pileta', d_pile,'SUM', d_salon,'Seguridad', d_seguri]\n",
    "df2 = df\n",
    "i = 0\n",
    "j = 1\n",
    "while i < len(dfs_list):\n",
    "    df2[dfs_list[i]] = dfs_list[j]\n",
    "    j = j + 2\n",
    "    i = i + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('df2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gráficos\n",
    "Debido a que las variables económicas referidas a precios e ingresos tienen una distribución asimétrica (existen muchos inmuebles de poco valor y pocos de alto valor), realizamos transformaciónes logarítmicas sobre dichas variables.\n",
    "\n",
    "El efecto que tendrá es que tomará la forma de una normal típica, lo que nos permite aprovechar todas las propiedades de dicha distribución, al mismo tiempo que la transformación tiene ciertas propiedades particulares a la hora de construir el modelo descriptivo. Particularmente, los valores que tomen las variables descriptivas no serán unitarias, sino que representarán porcentajes de variación del precio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_price'] = df.price.apply(np.log)\n",
    "df['log_price_aprox_usd'] = df.price_aprox_usd.apply(np.log)\n",
    "df['log_price_usd_per_m2'] = df.price_usd_per_m2.apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(df.price.loc[(~df.price.isnull())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar en el gráfico, existen valores extremos, lo que le da la larga cola. Además, al estar trabajando con precios en pesos, las magnitudes se ven exageradas, por lo que trabajeremos con los precios en dólares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df.price_aprox_usd == df.price_aprox_usd.max()].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente gráfico es esencialmente el mismo que el anterior, pero en dólares, lo que permite apreciar el kernel ya que las magnitudes son menores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.price_aprox_usd.loc[(~df.price.isnull())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos un boxplot para ver los outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df.price_aprox_usd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos algunos inmuebles con valores por encima de 10 millones de dólares, por lo que procedemos a revisarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.price_aprox_usd > 10000000].filter(['price_aprox_usd', 'lat', 'rooms', 'amb_tit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprovechamos el hecho de que les falta información de variables descriptivas para descartarlos y que son pocas observaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df.price_aprox_usd > 10000000].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora buscamos outliers en la variable `price_usd_per_m2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df.price_usd_per_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que existen inmuebles con valores mayores a USD 50.000 por metro cuadrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.price_usd_per_m2 > 50000].filter(['price_aprox_usd', 'localidad','lat', 'rooms', 'amb_tit','surface_total_in_m2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a descartarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df.price_usd_per_m2 > 50000].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df.price_usd_per_m2); 'Ejecutamos el mismo boxplot de recién para verificar los cambios'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos un gráfico para ver la distribución de precios en dólares según tipo de inmueble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, vars=['price_aprox_usd'], hue='property_type', height=7, markers='property_type'); 'PH en Azul, \\\n",
    "apartment en Naranja, house en Verde y store en Rojo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora realizamos el mismo gráfico pero sobre `log_price_aprox_usd`, para apreciar la transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, vars=['log_price_aprox_usd'], hue='property_type', height=7, markers='property_type' ); 'PH en Azul, \\\n",
    "apartment en Naranja, house en Verde y store en Rojo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y también sobre `price_usd_per_m2`y `log_price_usd_per_m2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, vars=['price_usd_per_m2'], hue='property_type', height=7, markers='property_type'); 'PH en Azul, \\\n",
    "apartment en Naranja, house en Verde y store en Rojo'\n",
    "plt.savefig('p_per_m2_usd.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, vars=['log_price_usd_per_m2'], hue='property_type', height=7, markers='property_type'); 'PH en Azul, \\\n",
    "apartment en Naranja, house en Verde y store en Rojo'\n",
    "plt.savefig('log_p_per_m2_usd.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos concentramos en la Ciudad Autónoma de Buenos Aires para ver qué barrios tienen el valor por metro cuadrado más elevado según la mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caba = df.loc[(df.provincia== 'Capital Federal')].groupby('localidad')\\\n",
    "                .price_usd_per_m2.median().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos los valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(caba.index, caba.values).set_xticklabels(labels=caba.index, rotation=90);\n",
    "plt.savefig('median_price.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de los polígonos de CABA en un nuevo data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrios = pd.read_csv('barrios.csv', encoding='latin1')\n",
    "barrios.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos una funcion para convertirlo en GeoDataFrame\n",
    "def from_wkt(df, wkt_column):\n",
    "    import shapely.wkt\n",
    "    df[\"coordinates\"]= df[wkt_column].apply(shapely.wkt.loads)\n",
    "    gdf = gpd.GeoDataFrame(barrios, geometry='coordinates')\n",
    "    return gdf\n",
    "\n",
    "barrios = from_wkt(barrios, \"WKT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que tenemos diferencias en los nombres de nuestro df original y el de barrios, procedemos a unificar los nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caba.index = caba.index.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caba.index = caba.index.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caba.rename({'NUNEZ':'NUÑEZ', 'VILLA GENERAL MITRE': 'VILLA GRAL. MITRE',\\\n",
    "                     'POMPEYA':'NUEVA POMPEYA', 'CONSTITUCIÓN':'CONSTITUCION' }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precios_barrios = barrios.merge(caba, how='left', left_on='BARRIO', right_on=caba.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caba.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precios_barrios.plot('price_usd_per_m2', figsize=(12,10), legend=True);\n",
    "plt.title('Mediana de precios por metro cuadrado en dólares');\n",
    "plt.savefig('mapa_precios.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,10), subplot_kw=dict(aspect='equal'))\n",
    "\n",
    "precios_barrios.plot(column='price_usd_per_m2', scheme='Quantiles', \n",
    "        k=5, cmap='GnBu', legend=True, ax=ax)\n",
    "\n",
    "plt.title('Mediana de precios por metro cuadrado en dólares por barrio por quintiles');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,10), subplot_kw=dict(aspect='equal'))\n",
    "\n",
    "precios_barrios.plot(column='price_usd_per_m2', scheme='Quantiles', \n",
    "        k=10, cmap='GnBu', legend=True, ax=ax, )\n",
    "\n",
    "plt.title('Mediana de precios por metro cuadrado en dólares por barrio por deciles');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.property_type ==df.property_type.unique()[0]] .rooms.hist(bins=20)\n",
    "plt.title('Distribución de cantidad de ambientes en PH');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.property_type ==df.property_type.unique()[1]] .rooms.hist(bins=20)\n",
    "plt.title('Distribución de cantidad de ambientes en apartment');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.property_type ==df.property_type.unique()[2]] .rooms.hist(bins=20)\n",
    "plt.title('Distribución de cantidad de ambientes en casas');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.property_type ==df.property_type.unique()[3]] .rooms.hist(bins=20)\n",
    "plt.title('Distribución de cantidad de ambientes en store');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiramos las columnas innecesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['floor', 'valores_invertidos', 'pozo', 'cuota', 'financ', 'pais', 'dor_desc',\n",
    "                 'bath_tit', 'bath_desc', 'amb_desc', 'dor_tit'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos la distribución de los metros cuadrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df.surface_covered_in_m2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.surface_covered_in_m2 > 30000].description.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar en las descripciones, los valores de los m2 son erróneos. Procedemos a dropearlos y graficamos nuevamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df.surface_covered_in_m2 > 30000].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df.surface_covered_in_m2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los outliers corresponden a locales, lo cual es factible si se tratara de galpones/fábricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['amb_tit', 'expenses', 'cubierta_sobre_total', 'total_sobre_cubierta', 'state_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalmente obtenemos los resultados de cuántas observaciones nos faltan, según la variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos los porcentajes de datos faltantes de cada columna luego de la limpieza\n",
    "for cols in df.columns:\n",
    "    nulos = df[cols].isnull().sum()\n",
    "    porcentaje = nulos/len(df)\n",
    "    print(f'{porcentaje*100:.0f}%', cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
